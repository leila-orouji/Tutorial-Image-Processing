{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\leila\\anaconda3\\pythonw.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How you can start mapping words into vector spaces\n",
    "# and how you can start looking at sentiment even visualizing how your model has lernt sentiment from the sense of words\n",
    "import tensorflow as tf\n",
    "\n",
    "print (tf.__version__)\n",
    "tf.enable_eager_execution()  #if needed\n",
    "\n",
    "!pip install -q tensorflow-datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "imdb, info = tfds.load (\"imdb_reviews\", with_info=True, as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "train_data, test_data = imdb['train'], imdb['test']\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "# str(s.tonumpy()) is needed in python3 instead of just s.numpy()\n",
    "for s,l in train_data :\n",
    "    training_sentences.append(str(s.numpy()))\n",
    "    training_labels.append(l.numpy())\n",
    "    \n",
    "for s,l in test_data :\n",
    "    testing_sentences.append(str(s.numpy()))\n",
    "    testing_labels.append(l.numpy())\n",
    "\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? b'this is the kind of film for a snowy sunday afternoon when the rest of the world can go ahead with its own business as you <OOV> into a big arm chair and <OOV> for a couple of hours wonderful performances from cher and nicolas cage as always gently row the plot along there are no <OOV> to cross no dangerous waters just a warm and witty <OOV> through new york life at its best a family film in every sense and one that deserves the praise it received '\n",
      "b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - ETA: 16:39 - loss: 0.6933 - acc: 0.50 - ETA: 2:27 - loss: 0.6933 - acc: 0.5223 - ETA: 1:29 - loss: 0.6932 - acc: 0.518 - ETA: 58s - loss: 0.6930 - acc: 0.516 - ETA: 45s - loss: 0.6928 - acc: 0.52 - ETA: 36s - loss: 0.6929 - acc: 0.51 - ETA: 30s - loss: 0.6930 - acc: 0.51 - ETA: 27s - loss: 0.6931 - acc: 0.51 - ETA: 26s - loss: 0.6931 - acc: 0.50 - ETA: 23s - loss: 0.6928 - acc: 0.51 - ETA: 22s - loss: 0.6927 - acc: 0.51 - ETA: 20s - loss: 0.6926 - acc: 0.51 - ETA: 19s - loss: 0.6925 - acc: 0.51 - ETA: 17s - loss: 0.6923 - acc: 0.51 - ETA: 16s - loss: 0.6923 - acc: 0.51 - ETA: 15s - loss: 0.6925 - acc: 0.51 - ETA: 14s - loss: 0.6924 - acc: 0.52 - ETA: 14s - loss: 0.6922 - acc: 0.51 - ETA: 13s - loss: 0.6917 - acc: 0.52 - ETA: 12s - loss: 0.6917 - acc: 0.52 - ETA: 12s - loss: 0.6918 - acc: 0.52 - ETA: 12s - loss: 0.6917 - acc: 0.52 - ETA: 11s - loss: 0.6917 - acc: 0.52 - ETA: 11s - loss: 0.6916 - acc: 0.52 - ETA: 11s - loss: 0.6914 - acc: 0.52 - ETA: 11s - loss: 0.6910 - acc: 0.52 - ETA: 10s - loss: 0.6908 - acc: 0.52 - ETA: 10s - loss: 0.6908 - acc: 0.53 - ETA: 10s - loss: 0.6905 - acc: 0.53 - ETA: 9s - loss: 0.6900 - acc: 0.5354 - ETA: 9s - loss: 0.6896 - acc: 0.537 - ETA: 9s - loss: 0.6894 - acc: 0.539 - ETA: 9s - loss: 0.6890 - acc: 0.542 - ETA: 9s - loss: 0.6884 - acc: 0.545 - ETA: 8s - loss: 0.6878 - acc: 0.548 - ETA: 8s - loss: 0.6867 - acc: 0.553 - ETA: 8s - loss: 0.6855 - acc: 0.557 - ETA: 8s - loss: 0.6840 - acc: 0.561 - ETA: 8s - loss: 0.6822 - acc: 0.566 - ETA: 7s - loss: 0.6806 - acc: 0.570 - ETA: 7s - loss: 0.6789 - acc: 0.574 - ETA: 7s - loss: 0.6771 - acc: 0.578 - ETA: 7s - loss: 0.6748 - acc: 0.582 - ETA: 7s - loss: 0.6730 - acc: 0.585 - ETA: 7s - loss: 0.6707 - acc: 0.589 - ETA: 6s - loss: 0.6677 - acc: 0.593 - ETA: 6s - loss: 0.6656 - acc: 0.597 - ETA: 6s - loss: 0.6620 - acc: 0.602 - ETA: 6s - loss: 0.6594 - acc: 0.604 - ETA: 6s - loss: 0.6555 - acc: 0.609 - ETA: 6s - loss: 0.6517 - acc: 0.613 - ETA: 6s - loss: 0.6478 - acc: 0.617 - ETA: 5s - loss: 0.6450 - acc: 0.621 - ETA: 5s - loss: 0.6418 - acc: 0.624 - ETA: 5s - loss: 0.6374 - acc: 0.628 - ETA: 5s - loss: 0.6336 - acc: 0.632 - ETA: 5s - loss: 0.6301 - acc: 0.635 - ETA: 5s - loss: 0.6267 - acc: 0.638 - ETA: 5s - loss: 0.6227 - acc: 0.641 - ETA: 5s - loss: 0.6205 - acc: 0.644 - ETA: 5s - loss: 0.6184 - acc: 0.646 - ETA: 4s - loss: 0.6147 - acc: 0.649 - ETA: 4s - loss: 0.6131 - acc: 0.651 - ETA: 4s - loss: 0.6100 - acc: 0.653 - ETA: 4s - loss: 0.6066 - acc: 0.656 - ETA: 4s - loss: 0.6030 - acc: 0.659 - ETA: 4s - loss: 0.6003 - acc: 0.661 - ETA: 4s - loss: 0.5982 - acc: 0.663 - ETA: 4s - loss: 0.5944 - acc: 0.667 - ETA: 4s - loss: 0.5913 - acc: 0.670 - ETA: 4s - loss: 0.5888 - acc: 0.672 - ETA: 4s - loss: 0.5857 - acc: 0.674 - ETA: 3s - loss: 0.5823 - acc: 0.677 - ETA: 3s - loss: 0.5801 - acc: 0.678 - ETA: 3s - loss: 0.5772 - acc: 0.681 - ETA: 3s - loss: 0.5752 - acc: 0.682 - ETA: 3s - loss: 0.5736 - acc: 0.684 - ETA: 3s - loss: 0.5725 - acc: 0.685 - ETA: 3s - loss: 0.5708 - acc: 0.686 - ETA: 3s - loss: 0.5697 - acc: 0.687 - ETA: 3s - loss: 0.5679 - acc: 0.689 - ETA: 3s - loss: 0.5660 - acc: 0.690 - ETA: 3s - loss: 0.5642 - acc: 0.692 - ETA: 3s - loss: 0.5625 - acc: 0.693 - ETA: 3s - loss: 0.5608 - acc: 0.694 - ETA: 2s - loss: 0.5586 - acc: 0.696 - ETA: 2s - loss: 0.5568 - acc: 0.698 - ETA: 2s - loss: 0.5549 - acc: 0.699 - ETA: 2s - loss: 0.5530 - acc: 0.700 - ETA: 2s - loss: 0.5502 - acc: 0.702 - ETA: 2s - loss: 0.5489 - acc: 0.703 - ETA: 2s - loss: 0.5473 - acc: 0.705 - ETA: 2s - loss: 0.5443 - acc: 0.707 - ETA: 2s - loss: 0.5423 - acc: 0.709 - ETA: 2s - loss: 0.5409 - acc: 0.710 - ETA: 2s - loss: 0.5386 - acc: 0.711 - ETA: 2s - loss: 0.5367 - acc: 0.713 - ETA: 1s - loss: 0.5348 - acc: 0.714 - ETA: 1s - loss: 0.5328 - acc: 0.716 - ETA: 1s - loss: 0.5316 - acc: 0.717 - ETA: 1s - loss: 0.5307 - acc: 0.718 - ETA: 1s - loss: 0.5286 - acc: 0.719 - ETA: 1s - loss: 0.5271 - acc: 0.720 - ETA: 1s - loss: 0.5253 - acc: 0.721 - ETA: 1s - loss: 0.5237 - acc: 0.722 - ETA: 1s - loss: 0.5219 - acc: 0.724 - ETA: 1s - loss: 0.5205 - acc: 0.725 - ETA: 1s - loss: 0.5190 - acc: 0.726 - ETA: 1s - loss: 0.5182 - acc: 0.727 - ETA: 1s - loss: 0.5169 - acc: 0.728 - ETA: 1s - loss: 0.5152 - acc: 0.729 - ETA: 1s - loss: 0.5135 - acc: 0.730 - ETA: 1s - loss: 0.5129 - acc: 0.730 - ETA: 0s - loss: 0.5112 - acc: 0.732 - ETA: 0s - loss: 0.5097 - acc: 0.733 - ETA: 0s - loss: 0.5086 - acc: 0.734 - ETA: 0s - loss: 0.5075 - acc: 0.735 - ETA: 0s - loss: 0.5067 - acc: 0.735 - ETA: 0s - loss: 0.5061 - acc: 0.736 - ETA: 0s - loss: 0.5047 - acc: 0.737 - ETA: 0s - loss: 0.5041 - acc: 0.737 - ETA: 0s - loss: 0.5024 - acc: 0.738 - ETA: 0s - loss: 0.5013 - acc: 0.739 - ETA: 0s - loss: 0.5001 - acc: 0.740 - ETA: 0s - loss: 0.4986 - acc: 0.741 - ETA: 0s - loss: 0.4978 - acc: 0.741 - ETA: 0s - loss: 0.4968 - acc: 0.742 - ETA: 0s - loss: 0.4956 - acc: 0.743 - ETA: 0s - loss: 0.4951 - acc: 0.743 - 11s 422us/sample - loss: 0.4950 - acc: 0.7439 - val_loss: 0.3567 - val_acc: 0.8398\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 24s - loss: 0.3430 - acc: 0.87 - ETA: 8s - loss: 0.2342 - acc: 0.9180 - ETA: 7s - loss: 0.2289 - acc: 0.921 - ETA: 7s - loss: 0.2264 - acc: 0.918 - ETA: 6s - loss: 0.2341 - acc: 0.916 - ETA: 7s - loss: 0.2355 - acc: 0.914 - ETA: 7s - loss: 0.2358 - acc: 0.915 - ETA: 7s - loss: 0.2353 - acc: 0.915 - ETA: 7s - loss: 0.2382 - acc: 0.914 - ETA: 7s - loss: 0.2385 - acc: 0.915 - ETA: 7s - loss: 0.2397 - acc: 0.915 - ETA: 7s - loss: 0.2385 - acc: 0.915 - ETA: 7s - loss: 0.2371 - acc: 0.915 - ETA: 7s - loss: 0.2398 - acc: 0.914 - ETA: 7s - loss: 0.2412 - acc: 0.913 - ETA: 6s - loss: 0.2441 - acc: 0.911 - ETA: 6s - loss: 0.2448 - acc: 0.911 - ETA: 6s - loss: 0.2429 - acc: 0.912 - ETA: 6s - loss: 0.2434 - acc: 0.910 - ETA: 6s - loss: 0.2464 - acc: 0.909 - ETA: 6s - loss: 0.2441 - acc: 0.910 - ETA: 6s - loss: 0.2459 - acc: 0.909 - ETA: 6s - loss: 0.2483 - acc: 0.908 - ETA: 6s - loss: 0.2475 - acc: 0.907 - ETA: 6s - loss: 0.2486 - acc: 0.906 - ETA: 6s - loss: 0.2479 - acc: 0.907 - ETA: 6s - loss: 0.2495 - acc: 0.906 - ETA: 6s - loss: 0.2471 - acc: 0.907 - ETA: 6s - loss: 0.2482 - acc: 0.905 - ETA: 6s - loss: 0.2488 - acc: 0.906 - ETA: 6s - loss: 0.2474 - acc: 0.906 - ETA: 6s - loss: 0.2478 - acc: 0.907 - ETA: 5s - loss: 0.2462 - acc: 0.907 - ETA: 5s - loss: 0.2471 - acc: 0.905 - ETA: 5s - loss: 0.2472 - acc: 0.906 - ETA: 5s - loss: 0.2489 - acc: 0.905 - ETA: 5s - loss: 0.2482 - acc: 0.906 - ETA: 5s - loss: 0.2475 - acc: 0.906 - ETA: 5s - loss: 0.2469 - acc: 0.906 - ETA: 5s - loss: 0.2458 - acc: 0.906 - ETA: 5s - loss: 0.2454 - acc: 0.907 - ETA: 5s - loss: 0.2457 - acc: 0.906 - ETA: 5s - loss: 0.2447 - acc: 0.906 - ETA: 5s - loss: 0.2447 - acc: 0.906 - ETA: 5s - loss: 0.2438 - acc: 0.907 - ETA: 5s - loss: 0.2424 - acc: 0.907 - ETA: 4s - loss: 0.2431 - acc: 0.907 - ETA: 4s - loss: 0.2420 - acc: 0.907 - ETA: 4s - loss: 0.2418 - acc: 0.908 - ETA: 4s - loss: 0.2410 - acc: 0.908 - ETA: 4s - loss: 0.2433 - acc: 0.907 - ETA: 4s - loss: 0.2434 - acc: 0.907 - ETA: 4s - loss: 0.2436 - acc: 0.907 - ETA: 4s - loss: 0.2443 - acc: 0.907 - ETA: 4s - loss: 0.2439 - acc: 0.907 - ETA: 4s - loss: 0.2448 - acc: 0.907 - ETA: 4s - loss: 0.2438 - acc: 0.907 - ETA: 4s - loss: 0.2439 - acc: 0.907 - ETA: 4s - loss: 0.2449 - acc: 0.907 - ETA: 4s - loss: 0.2448 - acc: 0.907 - ETA: 3s - loss: 0.2456 - acc: 0.907 - ETA: 3s - loss: 0.2455 - acc: 0.907 - ETA: 3s - loss: 0.2461 - acc: 0.907 - ETA: 3s - loss: 0.2468 - acc: 0.906 - ETA: 3s - loss: 0.2456 - acc: 0.907 - ETA: 3s - loss: 0.2457 - acc: 0.907 - ETA: 3s - loss: 0.2452 - acc: 0.907 - ETA: 3s - loss: 0.2465 - acc: 0.906 - ETA: 3s - loss: 0.2459 - acc: 0.906 - ETA: 3s - loss: 0.2450 - acc: 0.907 - ETA: 3s - loss: 0.2447 - acc: 0.907 - ETA: 3s - loss: 0.2445 - acc: 0.907 - ETA: 3s - loss: 0.2445 - acc: 0.907 - ETA: 3s - loss: 0.2443 - acc: 0.907 - ETA: 3s - loss: 0.2438 - acc: 0.908 - ETA: 3s - loss: 0.2437 - acc: 0.908 - ETA: 2s - loss: 0.2436 - acc: 0.908 - ETA: 2s - loss: 0.2441 - acc: 0.907 - ETA: 2s - loss: 0.2440 - acc: 0.907 - ETA: 2s - loss: 0.2448 - acc: 0.907 - ETA: 2s - loss: 0.2441 - acc: 0.907 - ETA: 2s - loss: 0.2436 - acc: 0.908 - ETA: 2s - loss: 0.2437 - acc: 0.908 - ETA: 2s - loss: 0.2437 - acc: 0.908 - ETA: 2s - loss: 0.2434 - acc: 0.908 - ETA: 2s - loss: 0.2432 - acc: 0.908 - ETA: 2s - loss: 0.2432 - acc: 0.908 - ETA: 2s - loss: 0.2428 - acc: 0.908 - ETA: 2s - loss: 0.2427 - acc: 0.908 - ETA: 2s - loss: 0.2427 - acc: 0.908 - ETA: 2s - loss: 0.2422 - acc: 0.909 - ETA: 2s - loss: 0.2419 - acc: 0.909 - ETA: 1s - loss: 0.2418 - acc: 0.909 - ETA: 1s - loss: 0.2420 - acc: 0.909 - ETA: 1s - loss: 0.2416 - acc: 0.909 - ETA: 1s - loss: 0.2414 - acc: 0.909 - ETA: 1s - loss: 0.2410 - acc: 0.909 - ETA: 1s - loss: 0.2410 - acc: 0.909 - ETA: 1s - loss: 0.2412 - acc: 0.909 - ETA: 1s - loss: 0.2413 - acc: 0.909 - ETA: 1s - loss: 0.2413 - acc: 0.909 - ETA: 1s - loss: 0.2417 - acc: 0.908 - ETA: 1s - loss: 0.2416 - acc: 0.908 - ETA: 1s - loss: 0.2418 - acc: 0.908 - ETA: 1s - loss: 0.2415 - acc: 0.908 - ETA: 1s - loss: 0.2419 - acc: 0.908 - ETA: 1s - loss: 0.2418 - acc: 0.908 - ETA: 1s - loss: 0.2421 - acc: 0.908 - ETA: 1s - loss: 0.2420 - acc: 0.908 - ETA: 0s - loss: 0.2415 - acc: 0.908 - ETA: 0s - loss: 0.2411 - acc: 0.908 - ETA: 0s - loss: 0.2407 - acc: 0.909 - ETA: 0s - loss: 0.2406 - acc: 0.908 - ETA: 0s - loss: 0.2411 - acc: 0.908 - ETA: 0s - loss: 0.2409 - acc: 0.908 - ETA: 0s - loss: 0.2411 - acc: 0.908 - ETA: 0s - loss: 0.2412 - acc: 0.908 - ETA: 0s - loss: 0.2412 - acc: 0.908 - ETA: 0s - loss: 0.2413 - acc: 0.908 - ETA: 0s - loss: 0.2411 - acc: 0.908 - ETA: 0s - loss: 0.2408 - acc: 0.908 - ETA: 0s - loss: 0.2412 - acc: 0.908 - ETA: 0s - loss: 0.2410 - acc: 0.908 - ETA: 0s - loss: 0.2409 - acc: 0.908 - ETA: 0s - loss: 0.2408 - acc: 0.908 - ETA: 0s - loss: 0.2407 - acc: 0.908 - 9s 357us/sample - loss: 0.2405 - acc: 0.9082 - val_loss: 0.3673 - val_acc: 0.8391\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 21s - loss: 0.1069 - acc: 0.96 - ETA: 10s - loss: 0.1398 - acc: 0.95 - ETA: 7s - loss: 0.1150 - acc: 0.9760 - ETA: 7s - loss: 0.1067 - acc: 0.975 - ETA: 6s - loss: 0.1081 - acc: 0.977 - ETA: 6s - loss: 0.1094 - acc: 0.975 - ETA: 6s - loss: 0.1061 - acc: 0.977 - ETA: 6s - loss: 0.1028 - acc: 0.978 - ETA: 6s - loss: 0.0995 - acc: 0.980 - ETA: 6s - loss: 0.1032 - acc: 0.979 - ETA: 6s - loss: 0.1012 - acc: 0.979 - ETA: 6s - loss: 0.1016 - acc: 0.979 - ETA: 6s - loss: 0.1000 - acc: 0.979 - ETA: 5s - loss: 0.0971 - acc: 0.981 - ETA: 5s - loss: 0.0982 - acc: 0.980 - ETA: 5s - loss: 0.0981 - acc: 0.980 - ETA: 5s - loss: 0.0968 - acc: 0.981 - ETA: 5s - loss: 0.0968 - acc: 0.981 - ETA: 5s - loss: 0.0973 - acc: 0.981 - ETA: 5s - loss: 0.0966 - acc: 0.981 - ETA: 5s - loss: 0.0957 - acc: 0.981 - ETA: 5s - loss: 0.0968 - acc: 0.980 - ETA: 5s - loss: 0.0963 - acc: 0.981 - ETA: 5s - loss: 0.0974 - acc: 0.980 - ETA: 5s - loss: 0.0971 - acc: 0.979 - ETA: 5s - loss: 0.0970 - acc: 0.980 - ETA: 5s - loss: 0.0965 - acc: 0.980 - ETA: 5s - loss: 0.0967 - acc: 0.980 - ETA: 5s - loss: 0.0958 - acc: 0.980 - ETA: 5s - loss: 0.0955 - acc: 0.980 - ETA: 5s - loss: 0.0956 - acc: 0.979 - ETA: 4s - loss: 0.0956 - acc: 0.979 - ETA: 4s - loss: 0.0962 - acc: 0.979 - ETA: 4s - loss: 0.0959 - acc: 0.979 - ETA: 4s - loss: 0.0958 - acc: 0.979 - ETA: 4s - loss: 0.0958 - acc: 0.979 - ETA: 4s - loss: 0.0957 - acc: 0.978 - ETA: 4s - loss: 0.0950 - acc: 0.979 - ETA: 4s - loss: 0.0950 - acc: 0.979 - ETA: 4s - loss: 0.0940 - acc: 0.979 - ETA: 4s - loss: 0.0937 - acc: 0.979 - ETA: 4s - loss: 0.0929 - acc: 0.980 - ETA: 4s - loss: 0.0925 - acc: 0.980 - ETA: 4s - loss: 0.0923 - acc: 0.980 - ETA: 4s - loss: 0.0923 - acc: 0.979 - ETA: 4s - loss: 0.0922 - acc: 0.979 - ETA: 4s - loss: 0.0914 - acc: 0.979 - ETA: 4s - loss: 0.0915 - acc: 0.979 - ETA: 4s - loss: 0.0917 - acc: 0.979 - ETA: 4s - loss: 0.0911 - acc: 0.979 - ETA: 3s - loss: 0.0914 - acc: 0.979 - ETA: 3s - loss: 0.0917 - acc: 0.979 - ETA: 3s - loss: 0.0910 - acc: 0.979 - ETA: 3s - loss: 0.0910 - acc: 0.979 - ETA: 3s - loss: 0.0907 - acc: 0.979 - ETA: 3s - loss: 0.0905 - acc: 0.979 - ETA: 3s - loss: 0.0906 - acc: 0.979 - ETA: 3s - loss: 0.0905 - acc: 0.979 - ETA: 3s - loss: 0.0902 - acc: 0.979 - ETA: 3s - loss: 0.0902 - acc: 0.979 - ETA: 3s - loss: 0.0904 - acc: 0.979 - ETA: 3s - loss: 0.0903 - acc: 0.979 - ETA: 3s - loss: 0.0902 - acc: 0.979 - ETA: 3s - loss: 0.0898 - acc: 0.979 - ETA: 3s - loss: 0.0895 - acc: 0.979 - ETA: 3s - loss: 0.0895 - acc: 0.979 - ETA: 3s - loss: 0.0894 - acc: 0.979 - ETA: 3s - loss: 0.0892 - acc: 0.979 - ETA: 2s - loss: 0.0892 - acc: 0.979 - ETA: 2s - loss: 0.0895 - acc: 0.979 - ETA: 2s - loss: 0.0903 - acc: 0.979 - ETA: 2s - loss: 0.0906 - acc: 0.979 - ETA: 2s - loss: 0.0914 - acc: 0.978 - ETA: 2s - loss: 0.0915 - acc: 0.978 - ETA: 2s - loss: 0.0915 - acc: 0.978 - ETA: 2s - loss: 0.0911 - acc: 0.978 - ETA: 2s - loss: 0.0905 - acc: 0.979 - ETA: 2s - loss: 0.0903 - acc: 0.979 - ETA: 2s - loss: 0.0903 - acc: 0.979 - ETA: 2s - loss: 0.0908 - acc: 0.979 - ETA: 2s - loss: 0.0905 - acc: 0.979 - ETA: 2s - loss: 0.0906 - acc: 0.978 - ETA: 2s - loss: 0.0905 - acc: 0.978 - ETA: 2s - loss: 0.0901 - acc: 0.978 - ETA: 2s - loss: 0.0900 - acc: 0.978 - ETA: 2s - loss: 0.0900 - acc: 0.978 - ETA: 1s - loss: 0.0904 - acc: 0.978 - ETA: 1s - loss: 0.0904 - acc: 0.978 - ETA: 1s - loss: 0.0903 - acc: 0.978 - ETA: 1s - loss: 0.0903 - acc: 0.978 - ETA: 1s - loss: 0.0902 - acc: 0.978 - ETA: 1s - loss: 0.0902 - acc: 0.978 - ETA: 1s - loss: 0.0904 - acc: 0.978 - ETA: 1s - loss: 0.0903 - acc: 0.978 - ETA: 1s - loss: 0.0904 - acc: 0.978 - ETA: 1s - loss: 0.0904 - acc: 0.978 - ETA: 1s - loss: 0.0905 - acc: 0.978 - ETA: 1s - loss: 0.0906 - acc: 0.977 - ETA: 1s - loss: 0.0906 - acc: 0.977 - ETA: 1s - loss: 0.0900 - acc: 0.978 - ETA: 1s - loss: 0.0901 - acc: 0.977 - ETA: 1s - loss: 0.0903 - acc: 0.977 - ETA: 1s - loss: 0.0906 - acc: 0.977 - ETA: 0s - loss: 0.0904 - acc: 0.977 - ETA: 0s - loss: 0.0902 - acc: 0.977 - ETA: 0s - loss: 0.0899 - acc: 0.977 - ETA: 0s - loss: 0.0896 - acc: 0.977 - ETA: 0s - loss: 0.0899 - acc: 0.977 - ETA: 0s - loss: 0.0899 - acc: 0.977 - ETA: 0s - loss: 0.0903 - acc: 0.977 - ETA: 0s - loss: 0.0898 - acc: 0.977 - ETA: 0s - loss: 0.0898 - acc: 0.977 - ETA: 0s - loss: 0.0895 - acc: 0.977 - ETA: 0s - loss: 0.0894 - acc: 0.977 - ETA: 0s - loss: 0.0894 - acc: 0.977 - ETA: 0s - loss: 0.0897 - acc: 0.977 - ETA: 0s - loss: 0.0896 - acc: 0.977 - ETA: 0s - loss: 0.0897 - acc: 0.977 - ETA: 0s - loss: 0.0893 - acc: 0.977 - ETA: 0s - loss: 0.0890 - acc: 0.977 - ETA: 0s - loss: 0.0887 - acc: 0.977 - ETA: 0s - loss: 0.0885 - acc: 0.978 - 9s 349us/sample - loss: 0.0885 - acc: 0.9780 - val_loss: 0.4516 - val_acc: 0.8263\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 12s - loss: 0.0387 - acc: 1.00 - ETA: 7s - loss: 0.0254 - acc: 1.0000 - ETA: 7s - loss: 0.0238 - acc: 0.997 - ETA: 6s - loss: 0.0241 - acc: 0.996 - ETA: 6s - loss: 0.0223 - acc: 0.997 - ETA: 6s - loss: 0.0223 - acc: 0.998 - ETA: 6s - loss: 0.0220 - acc: 0.998 - ETA: 6s - loss: 0.0219 - acc: 0.998 - ETA: 6s - loss: 0.0219 - acc: 0.998 - ETA: 6s - loss: 0.0212 - acc: 0.999 - ETA: 6s - loss: 0.0219 - acc: 0.998 - ETA: 5s - loss: 0.0220 - acc: 0.998 - ETA: 5s - loss: 0.0217 - acc: 0.998 - ETA: 5s - loss: 0.0225 - acc: 0.998 - ETA: 5s - loss: 0.0237 - acc: 0.998 - ETA: 5s - loss: 0.0250 - acc: 0.997 - ETA: 5s - loss: 0.0245 - acc: 0.997 - ETA: 5s - loss: 0.0243 - acc: 0.997 - ETA: 5s - loss: 0.0243 - acc: 0.997 - ETA: 5s - loss: 0.0240 - acc: 0.997 - ETA: 5s - loss: 0.0237 - acc: 0.997 - ETA: 5s - loss: 0.0238 - acc: 0.997 - ETA: 5s - loss: 0.0242 - acc: 0.997 - ETA: 5s - loss: 0.0240 - acc: 0.997 - ETA: 5s - loss: 0.0236 - acc: 0.997 - ETA: 5s - loss: 0.0240 - acc: 0.997 - ETA: 5s - loss: 0.0245 - acc: 0.997 - ETA: 5s - loss: 0.0243 - acc: 0.997 - ETA: 5s - loss: 0.0243 - acc: 0.997 - ETA: 4s - loss: 0.0242 - acc: 0.997 - ETA: 4s - loss: 0.0245 - acc: 0.997 - ETA: 4s - loss: 0.0244 - acc: 0.997 - ETA: 4s - loss: 0.0245 - acc: 0.997 - ETA: 4s - loss: 0.0242 - acc: 0.997 - ETA: 4s - loss: 0.0239 - acc: 0.997 - ETA: 4s - loss: 0.0237 - acc: 0.997 - ETA: 4s - loss: 0.0235 - acc: 0.997 - ETA: 4s - loss: 0.0236 - acc: 0.997 - ETA: 4s - loss: 0.0235 - acc: 0.997 - ETA: 4s - loss: 0.0234 - acc: 0.997 - ETA: 4s - loss: 0.0231 - acc: 0.997 - ETA: 4s - loss: 0.0228 - acc: 0.997 - ETA: 4s - loss: 0.0226 - acc: 0.997 - ETA: 4s - loss: 0.0224 - acc: 0.997 - ETA: 4s - loss: 0.0228 - acc: 0.997 - ETA: 4s - loss: 0.0226 - acc: 0.997 - ETA: 4s - loss: 0.0226 - acc: 0.997 - ETA: 3s - loss: 0.0225 - acc: 0.997 - ETA: 3s - loss: 0.0223 - acc: 0.997 - ETA: 3s - loss: 0.0221 - acc: 0.997 - ETA: 3s - loss: 0.0219 - acc: 0.997 - ETA: 3s - loss: 0.0218 - acc: 0.997 - ETA: 3s - loss: 0.0217 - acc: 0.998 - ETA: 3s - loss: 0.0215 - acc: 0.998 - ETA: 3s - loss: 0.0219 - acc: 0.998 - ETA: 3s - loss: 0.0217 - acc: 0.998 - ETA: 3s - loss: 0.0216 - acc: 0.998 - ETA: 3s - loss: 0.0214 - acc: 0.998 - ETA: 3s - loss: 0.0217 - acc: 0.997 - ETA: 3s - loss: 0.0221 - acc: 0.997 - ETA: 3s - loss: 0.0220 - acc: 0.997 - ETA: 3s - loss: 0.0219 - acc: 0.997 - ETA: 3s - loss: 0.0217 - acc: 0.997 - ETA: 3s - loss: 0.0217 - acc: 0.997 - ETA: 3s - loss: 0.0217 - acc: 0.997 - ETA: 2s - loss: 0.0216 - acc: 0.997 - ETA: 2s - loss: 0.0219 - acc: 0.997 - ETA: 2s - loss: 0.0218 - acc: 0.997 - ETA: 2s - loss: 0.0217 - acc: 0.997 - ETA: 2s - loss: 0.0222 - acc: 0.997 - ETA: 2s - loss: 0.0221 - acc: 0.997 - ETA: 2s - loss: 0.0219 - acc: 0.997 - ETA: 2s - loss: 0.0223 - acc: 0.997 - ETA: 2s - loss: 0.0225 - acc: 0.997 - ETA: 2s - loss: 0.0229 - acc: 0.997 - ETA: 2s - loss: 0.0229 - acc: 0.997 - ETA: 2s - loss: 0.0231 - acc: 0.997 - ETA: 2s - loss: 0.0229 - acc: 0.997 - ETA: 2s - loss: 0.0229 - acc: 0.997 - ETA: 2s - loss: 0.0227 - acc: 0.997 - ETA: 2s - loss: 0.0228 - acc: 0.997 - ETA: 2s - loss: 0.0227 - acc: 0.997 - ETA: 2s - loss: 0.0227 - acc: 0.997 - ETA: 1s - loss: 0.0227 - acc: 0.997 - ETA: 1s - loss: 0.0225 - acc: 0.997 - ETA: 1s - loss: 0.0228 - acc: 0.997 - ETA: 1s - loss: 0.0226 - acc: 0.997 - ETA: 1s - loss: 0.0225 - acc: 0.997 - ETA: 1s - loss: 0.0226 - acc: 0.997 - ETA: 1s - loss: 0.0225 - acc: 0.997 - ETA: 1s - loss: 0.0225 - acc: 0.997 - ETA: 1s - loss: 0.0226 - acc: 0.997 - ETA: 1s - loss: 0.0229 - acc: 0.997 - ETA: 1s - loss: 0.0228 - acc: 0.997 - ETA: 1s - loss: 0.0232 - acc: 0.997 - ETA: 1s - loss: 0.0232 - acc: 0.997 - ETA: 1s - loss: 0.0232 - acc: 0.997 - ETA: 1s - loss: 0.0230 - acc: 0.997 - ETA: 1s - loss: 0.0230 - acc: 0.997 - ETA: 1s - loss: 0.0229 - acc: 0.997 - ETA: 1s - loss: 0.0228 - acc: 0.997 - ETA: 0s - loss: 0.0230 - acc: 0.997 - ETA: 0s - loss: 0.0230 - acc: 0.997 - ETA: 0s - loss: 0.0229 - acc: 0.997 - ETA: 0s - loss: 0.0228 - acc: 0.997 - ETA: 0s - loss: 0.0227 - acc: 0.997 - ETA: 0s - loss: 0.0227 - acc: 0.997 - ETA: 0s - loss: 0.0227 - acc: 0.997 - ETA: 0s - loss: 0.0228 - acc: 0.997 - ETA: 0s - loss: 0.0227 - acc: 0.997 - ETA: 0s - loss: 0.0226 - acc: 0.997 - ETA: 0s - loss: 0.0225 - acc: 0.997 - ETA: 0s - loss: 0.0225 - acc: 0.997 - ETA: 0s - loss: 0.0226 - acc: 0.997 - ETA: 0s - loss: 0.0226 - acc: 0.997 - ETA: 0s - loss: 0.0225 - acc: 0.997 - ETA: 0s - loss: 0.0223 - acc: 0.997 - ETA: 0s - loss: 0.0223 - acc: 0.997 - ETA: 0s - loss: 0.0223 - acc: 0.997 - ETA: 0s - loss: 0.0223 - acc: 0.997 - 9s 346us/sample - loss: 0.0222 - acc: 0.9971 - val_loss: 0.5323 - val_acc: 0.8250\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 17s - loss: 0.0066 - acc: 1.00 - ETA: 9s - loss: 0.0164 - acc: 0.9948 - ETA: 7s - loss: 0.0108 - acc: 0.997 - ETA: 6s - loss: 0.0093 - acc: 0.998 - ETA: 6s - loss: 0.0087 - acc: 0.998 - ETA: 6s - loss: 0.0082 - acc: 0.999 - ETA: 6s - loss: 0.0080 - acc: 0.999 - ETA: 6s - loss: 0.0078 - acc: 0.999 - ETA: 6s - loss: 0.0076 - acc: 0.999 - ETA: 6s - loss: 0.0075 - acc: 0.999 - ETA: 5s - loss: 0.0073 - acc: 0.999 - ETA: 5s - loss: 0.0072 - acc: 0.999 - ETA: 5s - loss: 0.0071 - acc: 0.999 - ETA: 5s - loss: 0.0069 - acc: 0.999 - ETA: 5s - loss: 0.0068 - acc: 0.999 - ETA: 5s - loss: 0.0066 - acc: 0.999 - ETA: 5s - loss: 0.0066 - acc: 0.999 - ETA: 5s - loss: 0.0065 - acc: 0.999 - ETA: 5s - loss: 0.0064 - acc: 0.999 - ETA: 5s - loss: 0.0064 - acc: 0.999 - ETA: 5s - loss: 0.0064 - acc: 0.999 - ETA: 5s - loss: 0.0063 - acc: 0.999 - ETA: 5s - loss: 0.0063 - acc: 0.999 - ETA: 5s - loss: 0.0063 - acc: 0.999 - ETA: 5s - loss: 0.0062 - acc: 0.999 - ETA: 5s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0064 - acc: 0.999 - ETA: 4s - loss: 0.0064 - acc: 0.999 - ETA: 4s - loss: 0.0064 - acc: 0.999 - ETA: 4s - loss: 0.0064 - acc: 0.999 - ETA: 4s - loss: 0.0063 - acc: 0.999 - ETA: 4s - loss: 0.0063 - acc: 0.999 - ETA: 4s - loss: 0.0066 - acc: 0.999 - ETA: 4s - loss: 0.0066 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0066 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0065 - acc: 0.999 - ETA: 4s - loss: 0.0064 - acc: 0.999 - ETA: 3s - loss: 0.0064 - acc: 0.999 - ETA: 3s - loss: 0.0064 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0064 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0064 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0063 - acc: 0.999 - ETA: 3s - loss: 0.0062 - acc: 0.999 - ETA: 3s - loss: 0.0062 - acc: 0.999 - ETA: 3s - loss: 0.0062 - acc: 0.999 - ETA: 3s - loss: 0.0062 - acc: 0.999 - ETA: 3s - loss: 0.0062 - acc: 0.999 - ETA: 3s - loss: 0.0061 - acc: 0.999 - ETA: 3s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0061 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0059 - acc: 0.999 - ETA: 2s - loss: 0.0059 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0060 - acc: 0.999 - ETA: 2s - loss: 0.0059 - acc: 0.999 - ETA: 2s - loss: 0.0059 - acc: 0.999 - ETA: 1s - loss: 0.0059 - acc: 0.999 - ETA: 1s - loss: 0.0059 - acc: 0.999 - ETA: 1s - loss: 0.0059 - acc: 0.999 - ETA: 1s - loss: 0.0059 - acc: 0.999 - ETA: 1s - loss: 0.0058 - acc: 0.999 - ETA: 1s - loss: 0.0058 - acc: 0.999 - ETA: 1s - loss: 0.0058 - acc: 0.999 - ETA: 1s - loss: 0.0058 - acc: 0.999 - ETA: 1s - loss: 0.0057 - acc: 0.999 - ETA: 1s - loss: 0.0057 - acc: 0.999 - ETA: 1s - loss: 0.0057 - acc: 0.999 - ETA: 1s - loss: 0.0057 - acc: 0.999 - ETA: 1s - loss: 0.0057 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 1s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0055 - acc: 0.999 - ETA: 0s - loss: 0.0055 - acc: 0.999 - ETA: 0s - loss: 0.0055 - acc: 0.999 - ETA: 0s - loss: 0.0055 - acc: 0.999 - ETA: 0s - loss: 0.0055 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0056 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - ETA: 0s - loss: 0.0057 - acc: 0.999 - 9s 364us/sample - loss: 0.0057 - acc: 0.9996 - val_loss: 0.6043 - val_acc: 0.8250\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 8s - loss: 0.0025 - acc: 1.000 - ETA: 6s - loss: 0.0022 - acc: 1.000 - ETA: 6s - loss: 0.0024 - acc: 1.000 - ETA: 6s - loss: 0.0024 - acc: 1.000 - ETA: 6s - loss: 0.0024 - acc: 1.000 - ETA: 6s - loss: 0.0024 - acc: 1.000 - ETA: 6s - loss: 0.0023 - acc: 1.000 - ETA: 6s - loss: 0.0023 - acc: 1.000 - ETA: 6s - loss: 0.0023 - acc: 1.000 - ETA: 6s - loss: 0.0023 - acc: 1.000 - ETA: 6s - loss: 0.0023 - acc: 1.000 - ETA: 6s - loss: 0.0022 - acc: 1.000 - ETA: 6s - loss: 0.0022 - acc: 1.000 - ETA: 6s - loss: 0.0022 - acc: 1.000 - ETA: 6s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0021 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0023 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0022 - acc: 1.000 - ETA: 5s - loss: 0.0021 - acc: 1.000 - ETA: 5s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0021 - acc: 1.000 - ETA: 4s - loss: 0.0020 - acc: 1.000 - ETA: 4s - loss: 0.0020 - acc: 1.000 - ETA: 4s - loss: 0.0020 - acc: 1.000 - ETA: 4s - loss: 0.0020 - acc: 1.000 - ETA: 4s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0020 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 3s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 2s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0019 - acc: 1.000 - ETA: 1s - loss: 0.0018 - acc: 1.000 - ETA: 1s - loss: 0.0018 - acc: 1.000 - ETA: 1s - loss: 0.0018 - acc: 1.000 - ETA: 1s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - 9s 356us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6559 - val_acc: 0.8250\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 10s - loss: 0.0013 - acc: 1.00 - ETA: 7s - loss: 0.0010 - acc: 1.0000 - ETA: 7s - loss: 0.0010 - acc: 1.000 - ETA: 7s - loss: 8.9029e-04 - acc: 1.000 - ETA: 7s - loss: 9.1328e-04 - acc: 1.000 - ETA: 6s - loss: 9.6026e-04 - acc: 1.000 - ETA: 6s - loss: 9.5210e-04 - acc: 1.000 - ETA: 6s - loss: 9.1713e-04 - acc: 1.000 - ETA: 6s - loss: 9.1788e-04 - acc: 1.000 - ETA: 6s - loss: 9.3112e-04 - acc: 1.000 - ETA: 6s - loss: 9.1869e-04 - acc: 1.000 - ETA: 6s - loss: 9.1779e-04 - acc: 1.000 - ETA: 6s - loss: 8.9777e-04 - acc: 1.000 - ETA: 6s - loss: 8.9608e-04 - acc: 1.000 - ETA: 6s - loss: 8.8530e-04 - acc: 1.000 - ETA: 6s - loss: 8.9872e-04 - acc: 1.000 - ETA: 6s - loss: 9.0054e-04 - acc: 1.000 - ETA: 6s - loss: 9.0214e-04 - acc: 1.000 - ETA: 6s - loss: 8.9810e-04 - acc: 1.000 - ETA: 5s - loss: 8.9521e-04 - acc: 1.000 - ETA: 5s - loss: 8.8623e-04 - acc: 1.000 - ETA: 5s - loss: 8.8280e-04 - acc: 1.000 - ETA: 5s - loss: 8.8795e-04 - acc: 1.000 - ETA: 5s - loss: 8.9061e-04 - acc: 1.000 - ETA: 5s - loss: 8.8638e-04 - acc: 1.000 - ETA: 5s - loss: 9.0302e-04 - acc: 1.000 - ETA: 5s - loss: 9.0876e-04 - acc: 1.000 - ETA: 5s - loss: 9.0633e-04 - acc: 1.000 - ETA: 5s - loss: 9.0802e-04 - acc: 1.000 - ETA: 5s - loss: 9.0692e-04 - acc: 1.000 - ETA: 5s - loss: 9.2683e-04 - acc: 1.000 - ETA: 5s - loss: 9.2388e-04 - acc: 1.000 - ETA: 5s - loss: 9.3896e-04 - acc: 1.000 - ETA: 5s - loss: 9.3479e-04 - acc: 1.000 - ETA: 5s - loss: 9.3102e-04 - acc: 1.000 - ETA: 5s - loss: 9.2982e-04 - acc: 1.000 - ETA: 5s - loss: 9.2520e-04 - acc: 1.000 - ETA: 5s - loss: 9.2375e-04 - acc: 1.000 - ETA: 5s - loss: 9.2350e-04 - acc: 1.000 - ETA: 5s - loss: 9.2354e-04 - acc: 1.000 - ETA: 5s - loss: 9.2210e-04 - acc: 1.000 - ETA: 5s - loss: 9.2580e-04 - acc: 1.000 - ETA: 5s - loss: 9.2610e-04 - acc: 1.000 - ETA: 5s - loss: 9.3233e-04 - acc: 1.000 - ETA: 5s - loss: 9.3351e-04 - acc: 1.000 - ETA: 5s - loss: 9.3222e-04 - acc: 1.000 - ETA: 5s - loss: 9.3203e-04 - acc: 1.000 - ETA: 5s - loss: 9.2768e-04 - acc: 1.000 - ETA: 5s - loss: 9.2472e-04 - acc: 1.000 - ETA: 5s - loss: 9.2409e-04 - acc: 1.000 - ETA: 5s - loss: 9.2034e-04 - acc: 1.000 - ETA: 5s - loss: 9.1873e-04 - acc: 1.000 - ETA: 5s - loss: 9.2258e-04 - acc: 1.000 - ETA: 5s - loss: 9.2089e-04 - acc: 1.000 - ETA: 5s - loss: 9.2463e-04 - acc: 1.000 - ETA: 5s - loss: 9.2190e-04 - acc: 1.000 - ETA: 4s - loss: 9.1982e-04 - acc: 1.000 - ETA: 4s - loss: 9.1942e-04 - acc: 1.000 - ETA: 4s - loss: 9.1654e-04 - acc: 1.000 - ETA: 4s - loss: 9.1738e-04 - acc: 1.000 - ETA: 4s - loss: 9.1727e-04 - acc: 1.000 - ETA: 4s - loss: 9.1813e-04 - acc: 1.000 - ETA: 4s - loss: 9.1806e-04 - acc: 1.000 - ETA: 4s - loss: 9.2162e-04 - acc: 1.000 - ETA: 4s - loss: 9.1977e-04 - acc: 1.000 - ETA: 4s - loss: 9.1893e-04 - acc: 1.000 - ETA: 4s - loss: 9.2393e-04 - acc: 1.000 - ETA: 4s - loss: 9.2220e-04 - acc: 1.000 - ETA: 4s - loss: 9.2018e-04 - acc: 1.000 - ETA: 4s - loss: 9.2155e-04 - acc: 1.000 - ETA: 4s - loss: 9.2564e-04 - acc: 1.000 - ETA: 4s - loss: 9.2623e-04 - acc: 1.000 - ETA: 4s - loss: 9.2453e-04 - acc: 1.000 - ETA: 3s - loss: 9.2274e-04 - acc: 1.000 - ETA: 3s - loss: 9.2072e-04 - acc: 1.000 - ETA: 3s - loss: 9.2064e-04 - acc: 1.000 - ETA: 3s - loss: 9.1801e-04 - acc: 1.000 - ETA: 3s - loss: 9.1483e-04 - acc: 1.000 - ETA: 3s - loss: 9.1148e-04 - acc: 1.000 - ETA: 3s - loss: 9.0782e-04 - acc: 1.000 - ETA: 3s - loss: 9.0347e-04 - acc: 1.000 - ETA: 3s - loss: 9.0268e-04 - acc: 1.000 - ETA: 3s - loss: 9.0155e-04 - acc: 1.000 - ETA: 3s - loss: 9.0041e-04 - acc: 1.000 - ETA: 3s - loss: 9.0071e-04 - acc: 1.000 - ETA: 3s - loss: 8.9893e-04 - acc: 1.000 - ETA: 3s - loss: 8.9796e-04 - acc: 1.000 - ETA: 3s - loss: 8.9617e-04 - acc: 1.000 - ETA: 3s - loss: 9.0047e-04 - acc: 1.000 - ETA: 3s - loss: 9.0099e-04 - acc: 1.000 - ETA: 3s - loss: 9.0064e-04 - acc: 1.000 - ETA: 3s - loss: 8.9808e-04 - acc: 1.000 - ETA: 3s - loss: 8.9582e-04 - acc: 1.000 - ETA: 3s - loss: 8.9404e-04 - acc: 1.000 - ETA: 2s - loss: 8.9315e-04 - acc: 1.000 - ETA: 2s - loss: 8.9165e-04 - acc: 1.000 - ETA: 2s - loss: 8.8987e-04 - acc: 1.000 - ETA: 2s - loss: 8.8843e-04 - acc: 1.000 - ETA: 2s - loss: 8.8677e-04 - acc: 1.000 - ETA: 2s - loss: 8.8534e-04 - acc: 1.000 - ETA: 2s - loss: 8.8105e-04 - acc: 1.000 - ETA: 2s - loss: 8.8166e-04 - acc: 1.000 - ETA: 2s - loss: 8.7969e-04 - acc: 1.000 - ETA: 2s - loss: 8.7710e-04 - acc: 1.000 - ETA: 2s - loss: 8.7622e-04 - acc: 1.000 - ETA: 2s - loss: 8.7447e-04 - acc: 1.000 - ETA: 2s - loss: 8.7275e-04 - acc: 1.000 - ETA: 2s - loss: 8.7283e-04 - acc: 1.000 - ETA: 2s - loss: 8.7069e-04 - acc: 1.000 - ETA: 2s - loss: 8.7223e-04 - acc: 1.000 - ETA: 2s - loss: 8.7272e-04 - acc: 1.000 - ETA: 2s - loss: 8.7178e-04 - acc: 1.000 - ETA: 1s - loss: 8.7082e-04 - acc: 1.000 - ETA: 1s - loss: 8.6872e-04 - acc: 1.000 - ETA: 1s - loss: 8.6772e-04 - acc: 1.000 - ETA: 1s - loss: 8.6596e-04 - acc: 1.000 - ETA: 1s - loss: 8.6429e-04 - acc: 1.000 - ETA: 1s - loss: 8.6269e-04 - acc: 1.000 - ETA: 1s - loss: 8.5968e-04 - acc: 1.000 - ETA: 1s - loss: 8.5831e-04 - acc: 1.000 - ETA: 1s - loss: 8.5617e-04 - acc: 1.000 - ETA: 1s - loss: 8.5589e-04 - acc: 1.000 - ETA: 1s - loss: 8.5376e-04 - acc: 1.000 - ETA: 1s - loss: 8.5159e-04 - acc: 1.000 - ETA: 1s - loss: 8.5105e-04 - acc: 1.000 - ETA: 1s - loss: 8.4909e-04 - acc: 1.000 - ETA: 1s - loss: 8.4889e-04 - acc: 1.000 - ETA: 1s - loss: 8.4797e-04 - acc: 1.000 - ETA: 1s - loss: 8.4734e-04 - acc: 1.000 - ETA: 1s - loss: 8.4583e-04 - acc: 1.000 - ETA: 1s - loss: 8.4318e-04 - acc: 1.000 - ETA: 1s - loss: 8.4270e-04 - acc: 1.000 - ETA: 1s - loss: 8.4098e-04 - acc: 1.000 - ETA: 1s - loss: 8.3985e-04 - acc: 1.000 - ETA: 0s - loss: 8.3829e-04 - acc: 1.000 - ETA: 0s - loss: 8.3594e-04 - acc: 1.000 - ETA: 0s - loss: 8.3461e-04 - acc: 1.000 - ETA: 0s - loss: 8.3206e-04 - acc: 1.000 - ETA: 0s - loss: 8.3038e-04 - acc: 1.000 - ETA: 0s - loss: 8.2801e-04 - acc: 1.000 - ETA: 0s - loss: 8.2547e-04 - acc: 1.000 - ETA: 0s - loss: 8.3055e-04 - acc: 1.000 - ETA: 0s - loss: 8.3052e-04 - acc: 1.000 - ETA: 0s - loss: 8.3178e-04 - acc: 1.000 - ETA: 0s - loss: 8.3180e-04 - acc: 1.000 - ETA: 0s - loss: 8.3097e-04 - acc: 1.000 - ETA: 0s - loss: 8.3068e-04 - acc: 1.000 - ETA: 0s - loss: 8.2955e-04 - acc: 1.000 - ETA: 0s - loss: 8.2819e-04 - acc: 1.000 - ETA: 0s - loss: 8.2570e-04 - acc: 1.000 - 11s 424us/sample - loss: 8.2512e-04 - acc: 1.0000 - val_loss: 0.6995 - val_acc: 0.8259\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 11s - loss: 7.1353e-04 - acc: 1.00 - ETA: 7s - loss: 4.8482e-04 - acc: 1.0000 - ETA: 7s - loss: 4.8814e-04 - acc: 1.000 - ETA: 6s - loss: 4.9071e-04 - acc: 1.000 - ETA: 6s - loss: 5.5706e-04 - acc: 1.000 - ETA: 6s - loss: 5.6340e-04 - acc: 1.000 - ETA: 6s - loss: 5.4925e-04 - acc: 1.000 - ETA: 5s - loss: 5.4477e-04 - acc: 1.000 - ETA: 6s - loss: 5.4310e-04 - acc: 1.000 - ETA: 5s - loss: 5.2626e-04 - acc: 1.000 - ETA: 5s - loss: 5.2165e-04 - acc: 1.000 - ETA: 5s - loss: 5.2613e-04 - acc: 1.000 - ETA: 5s - loss: 5.2108e-04 - acc: 1.000 - ETA: 5s - loss: 5.3600e-04 - acc: 1.000 - ETA: 5s - loss: 5.3169e-04 - acc: 1.000 - ETA: 5s - loss: 5.2635e-04 - acc: 1.000 - ETA: 5s - loss: 5.2915e-04 - acc: 1.000 - ETA: 5s - loss: 5.2198e-04 - acc: 1.000 - ETA: 5s - loss: 5.2788e-04 - acc: 1.000 - ETA: 5s - loss: 5.3205e-04 - acc: 1.000 - ETA: 5s - loss: 5.3017e-04 - acc: 1.000 - ETA: 5s - loss: 5.2562e-04 - acc: 1.000 - ETA: 5s - loss: 5.2038e-04 - acc: 1.000 - ETA: 5s - loss: 5.1641e-04 - acc: 1.000 - ETA: 5s - loss: 5.1150e-04 - acc: 1.000 - ETA: 5s - loss: 5.1003e-04 - acc: 1.000 - ETA: 5s - loss: 5.0944e-04 - acc: 1.000 - ETA: 5s - loss: 5.0928e-04 - acc: 1.000 - ETA: 5s - loss: 5.0718e-04 - acc: 1.000 - ETA: 5s - loss: 5.0809e-04 - acc: 1.000 - ETA: 4s - loss: 5.0038e-04 - acc: 1.000 - ETA: 4s - loss: 4.9999e-04 - acc: 1.000 - ETA: 4s - loss: 4.9658e-04 - acc: 1.000 - ETA: 4s - loss: 4.9613e-04 - acc: 1.000 - ETA: 4s - loss: 4.9329e-04 - acc: 1.000 - ETA: 4s - loss: 4.9010e-04 - acc: 1.000 - ETA: 4s - loss: 4.8983e-04 - acc: 1.000 - ETA: 4s - loss: 4.9121e-04 - acc: 1.000 - ETA: 4s - loss: 4.9266e-04 - acc: 1.000 - ETA: 4s - loss: 4.8901e-04 - acc: 1.000 - ETA: 4s - loss: 4.8765e-04 - acc: 1.000 - ETA: 4s - loss: 4.8619e-04 - acc: 1.000 - ETA: 4s - loss: 4.8578e-04 - acc: 1.000 - ETA: 4s - loss: 4.8438e-04 - acc: 1.000 - ETA: 4s - loss: 4.8596e-04 - acc: 1.000 - ETA: 4s - loss: 4.8459e-04 - acc: 1.000 - ETA: 4s - loss: 4.8268e-04 - acc: 1.000 - ETA: 4s - loss: 4.8292e-04 - acc: 1.000 - ETA: 4s - loss: 4.8404e-04 - acc: 1.000 - ETA: 3s - loss: 4.8587e-04 - acc: 1.000 - ETA: 3s - loss: 4.8390e-04 - acc: 1.000 - ETA: 3s - loss: 4.8404e-04 - acc: 1.000 - ETA: 3s - loss: 4.8191e-04 - acc: 1.000 - ETA: 3s - loss: 4.8163e-04 - acc: 1.000 - ETA: 3s - loss: 4.8115e-04 - acc: 1.000 - ETA: 3s - loss: 4.7958e-04 - acc: 1.000 - ETA: 3s - loss: 4.7843e-04 - acc: 1.000 - ETA: 3s - loss: 4.7736e-04 - acc: 1.000 - ETA: 3s - loss: 4.7637e-04 - acc: 1.000 - ETA: 3s - loss: 4.7696e-04 - acc: 1.000 - ETA: 3s - loss: 4.7633e-04 - acc: 1.000 - ETA: 3s - loss: 4.7478e-04 - acc: 1.000 - ETA: 3s - loss: 4.7907e-04 - acc: 1.000 - ETA: 3s - loss: 4.8243e-04 - acc: 1.000 - ETA: 3s - loss: 4.8276e-04 - acc: 1.000 - ETA: 3s - loss: 4.8281e-04 - acc: 1.000 - ETA: 3s - loss: 4.8067e-04 - acc: 1.000 - ETA: 2s - loss: 4.8091e-04 - acc: 1.000 - ETA: 2s - loss: 4.7877e-04 - acc: 1.000 - ETA: 2s - loss: 4.7702e-04 - acc: 1.000 - ETA: 2s - loss: 4.7707e-04 - acc: 1.000 - ETA: 2s - loss: 4.7722e-04 - acc: 1.000 - ETA: 2s - loss: 4.7585e-04 - acc: 1.000 - ETA: 2s - loss: 4.7622e-04 - acc: 1.000 - ETA: 2s - loss: 4.7449e-04 - acc: 1.000 - ETA: 2s - loss: 4.7302e-04 - acc: 1.000 - ETA: 2s - loss: 4.7227e-04 - acc: 1.000 - ETA: 2s - loss: 4.7226e-04 - acc: 1.000 - ETA: 2s - loss: 4.7192e-04 - acc: 1.000 - ETA: 2s - loss: 4.7151e-04 - acc: 1.000 - ETA: 2s - loss: 4.7030e-04 - acc: 1.000 - ETA: 2s - loss: 4.7323e-04 - acc: 1.000 - ETA: 2s - loss: 4.7121e-04 - acc: 1.000 - ETA: 2s - loss: 4.7148e-04 - acc: 1.000 - ETA: 2s - loss: 4.7109e-04 - acc: 1.000 - ETA: 2s - loss: 4.7286e-04 - acc: 1.000 - ETA: 1s - loss: 4.7306e-04 - acc: 1.000 - ETA: 1s - loss: 4.7284e-04 - acc: 1.000 - ETA: 1s - loss: 4.7227e-04 - acc: 1.000 - ETA: 1s - loss: 4.7069e-04 - acc: 1.000 - ETA: 1s - loss: 4.6985e-04 - acc: 1.000 - ETA: 1s - loss: 4.6835e-04 - acc: 1.000 - ETA: 1s - loss: 4.6721e-04 - acc: 1.000 - ETA: 1s - loss: 4.6612e-04 - acc: 1.000 - ETA: 1s - loss: 4.6610e-04 - acc: 1.000 - ETA: 1s - loss: 4.6621e-04 - acc: 1.000 - ETA: 1s - loss: 4.6540e-04 - acc: 1.000 - ETA: 1s - loss: 4.6454e-04 - acc: 1.000 - ETA: 1s - loss: 4.6416e-04 - acc: 1.000 - ETA: 1s - loss: 4.6245e-04 - acc: 1.000 - ETA: 1s - loss: 4.6105e-04 - acc: 1.000 - ETA: 1s - loss: 4.6041e-04 - acc: 1.000 - ETA: 1s - loss: 4.5948e-04 - acc: 1.000 - ETA: 1s - loss: 4.5832e-04 - acc: 1.000 - ETA: 0s - loss: 4.5727e-04 - acc: 1.000 - ETA: 0s - loss: 4.5725e-04 - acc: 1.000 - ETA: 0s - loss: 4.5632e-04 - acc: 1.000 - ETA: 0s - loss: 4.5555e-04 - acc: 1.000 - ETA: 0s - loss: 4.5448e-04 - acc: 1.000 - ETA: 0s - loss: 4.5381e-04 - acc: 1.000 - ETA: 0s - loss: 4.5439e-04 - acc: 1.000 - ETA: 0s - loss: 4.5358e-04 - acc: 1.000 - ETA: 0s - loss: 4.5383e-04 - acc: 1.000 - ETA: 0s - loss: 4.5336e-04 - acc: 1.000 - ETA: 0s - loss: 4.5207e-04 - acc: 1.000 - ETA: 0s - loss: 4.5085e-04 - acc: 1.000 - ETA: 0s - loss: 4.5078e-04 - acc: 1.000 - ETA: 0s - loss: 4.4996e-04 - acc: 1.000 - ETA: 0s - loss: 4.4865e-04 - acc: 1.000 - ETA: 0s - loss: 4.4845e-04 - acc: 1.000 - ETA: 0s - loss: 4.4779e-04 - acc: 1.000 - ETA: 0s - loss: 4.4698e-04 - acc: 1.000 - 9s 355us/sample - loss: 4.4619e-04 - acc: 1.0000 - val_loss: 0.7383 - val_acc: 0.8264\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 9s - loss: 5.3140e-04 - acc: 1.000 - ETA: 6s - loss: 3.6312e-04 - acc: 1.000 - ETA: 6s - loss: 3.1959e-04 - acc: 1.000 - ETA: 6s - loss: 3.1375e-04 - acc: 1.000 - ETA: 6s - loss: 2.9839e-04 - acc: 1.000 - ETA: 7s - loss: 2.9277e-04 - acc: 1.000 - ETA: 6s - loss: 2.9515e-04 - acc: 1.000 - ETA: 6s - loss: 2.9411e-04 - acc: 1.000 - ETA: 6s - loss: 3.0248e-04 - acc: 1.000 - ETA: 6s - loss: 3.0804e-04 - acc: 1.000 - ETA: 6s - loss: 3.0716e-04 - acc: 1.000 - ETA: 6s - loss: 2.9781e-04 - acc: 1.000 - ETA: 6s - loss: 3.0441e-04 - acc: 1.000 - ETA: 6s - loss: 3.0186e-04 - acc: 1.000 - ETA: 6s - loss: 3.3470e-04 - acc: 1.000 - ETA: 6s - loss: 3.3280e-04 - acc: 1.000 - ETA: 6s - loss: 3.2622e-04 - acc: 1.000 - ETA: 6s - loss: 3.2403e-04 - acc: 1.000 - ETA: 6s - loss: 3.2021e-04 - acc: 1.000 - ETA: 5s - loss: 3.1768e-04 - acc: 1.000 - ETA: 5s - loss: 3.1568e-04 - acc: 1.000 - ETA: 5s - loss: 3.0972e-04 - acc: 1.000 - ETA: 5s - loss: 3.1454e-04 - acc: 1.000 - ETA: 5s - loss: 3.1212e-04 - acc: 1.000 - ETA: 5s - loss: 3.1233e-04 - acc: 1.000 - ETA: 5s - loss: 3.1082e-04 - acc: 1.000 - ETA: 5s - loss: 3.1377e-04 - acc: 1.000 - ETA: 5s - loss: 3.1072e-04 - acc: 1.000 - ETA: 5s - loss: 3.0882e-04 - acc: 1.000 - ETA: 5s - loss: 3.0769e-04 - acc: 1.000 - ETA: 5s - loss: 3.0710e-04 - acc: 1.000 - ETA: 5s - loss: 3.0608e-04 - acc: 1.000 - ETA: 5s - loss: 3.0537e-04 - acc: 1.000 - ETA: 5s - loss: 3.0386e-04 - acc: 1.000 - ETA: 5s - loss: 3.0416e-04 - acc: 1.000 - ETA: 5s - loss: 3.0503e-04 - acc: 1.000 - ETA: 5s - loss: 3.0291e-04 - acc: 1.000 - ETA: 5s - loss: 3.0230e-04 - acc: 1.000 - ETA: 5s - loss: 3.0146e-04 - acc: 1.000 - ETA: 5s - loss: 3.0229e-04 - acc: 1.000 - ETA: 5s - loss: 2.9951e-04 - acc: 1.000 - ETA: 5s - loss: 2.9981e-04 - acc: 1.000 - ETA: 4s - loss: 2.9757e-04 - acc: 1.000 - ETA: 4s - loss: 2.9745e-04 - acc: 1.000 - ETA: 4s - loss: 2.9689e-04 - acc: 1.000 - ETA: 4s - loss: 2.9663e-04 - acc: 1.000 - ETA: 4s - loss: 2.9568e-04 - acc: 1.000 - ETA: 4s - loss: 2.9510e-04 - acc: 1.000 - ETA: 4s - loss: 2.9442e-04 - acc: 1.000 - ETA: 4s - loss: 2.9456e-04 - acc: 1.000 - ETA: 4s - loss: 2.9314e-04 - acc: 1.000 - ETA: 4s - loss: 2.9231e-04 - acc: 1.000 - ETA: 4s - loss: 2.9267e-04 - acc: 1.000 - ETA: 4s - loss: 2.9262e-04 - acc: 1.000 - ETA: 4s - loss: 2.9120e-04 - acc: 1.000 - ETA: 4s - loss: 2.9103e-04 - acc: 1.000 - ETA: 4s - loss: 2.9087e-04 - acc: 1.000 - ETA: 4s - loss: 2.9055e-04 - acc: 1.000 - ETA: 4s - loss: 2.9052e-04 - acc: 1.000 - ETA: 4s - loss: 2.9088e-04 - acc: 1.000 - ETA: 4s - loss: 2.9085e-04 - acc: 1.000 - ETA: 4s - loss: 2.9033e-04 - acc: 1.000 - ETA: 4s - loss: 2.8954e-04 - acc: 1.000 - ETA: 4s - loss: 2.8902e-04 - acc: 1.000 - ETA: 4s - loss: 2.8759e-04 - acc: 1.000 - ETA: 4s - loss: 2.8693e-04 - acc: 1.000 - ETA: 4s - loss: 2.8659e-04 - acc: 1.000 - ETA: 3s - loss: 2.8590e-04 - acc: 1.000 - ETA: 3s - loss: 2.8607e-04 - acc: 1.000 - ETA: 3s - loss: 2.8497e-04 - acc: 1.000 - ETA: 3s - loss: 2.8562e-04 - acc: 1.000 - ETA: 3s - loss: 2.8486e-04 - acc: 1.000 - ETA: 3s - loss: 2.8500e-04 - acc: 1.000 - ETA: 3s - loss: 2.8431e-04 - acc: 1.000 - ETA: 3s - loss: 2.8352e-04 - acc: 1.000 - ETA: 3s - loss: 2.8417e-04 - acc: 1.000 - ETA: 3s - loss: 2.8365e-04 - acc: 1.000 - ETA: 3s - loss: 2.8282e-04 - acc: 1.000 - ETA: 3s - loss: 2.8286e-04 - acc: 1.000 - ETA: 3s - loss: 2.8315e-04 - acc: 1.000 - ETA: 3s - loss: 2.8283e-04 - acc: 1.000 - ETA: 3s - loss: 2.8173e-04 - acc: 1.000 - ETA: 3s - loss: 2.8142e-04 - acc: 1.000 - ETA: 3s - loss: 2.8145e-04 - acc: 1.000 - ETA: 3s - loss: 2.8076e-04 - acc: 1.000 - ETA: 2s - loss: 2.8000e-04 - acc: 1.000 - ETA: 2s - loss: 2.7930e-04 - acc: 1.000 - ETA: 2s - loss: 2.7913e-04 - acc: 1.000 - ETA: 2s - loss: 2.7893e-04 - acc: 1.000 - ETA: 2s - loss: 2.7846e-04 - acc: 1.000 - ETA: 2s - loss: 2.7760e-04 - acc: 1.000 - ETA: 2s - loss: 2.7803e-04 - acc: 1.000 - ETA: 2s - loss: 2.7748e-04 - acc: 1.000 - ETA: 2s - loss: 2.7666e-04 - acc: 1.000 - ETA: 2s - loss: 2.7612e-04 - acc: 1.000 - ETA: 2s - loss: 2.7516e-04 - acc: 1.000 - ETA: 2s - loss: 2.7492e-04 - acc: 1.000 - ETA: 2s - loss: 2.7582e-04 - acc: 1.000 - ETA: 2s - loss: 2.7526e-04 - acc: 1.000 - ETA: 2s - loss: 2.7521e-04 - acc: 1.000 - ETA: 1s - loss: 2.7466e-04 - acc: 1.000 - ETA: 1s - loss: 2.7408e-04 - acc: 1.000 - ETA: 1s - loss: 2.7335e-04 - acc: 1.000 - ETA: 1s - loss: 2.7283e-04 - acc: 1.000 - ETA: 1s - loss: 2.7201e-04 - acc: 1.000 - ETA: 1s - loss: 2.7150e-04 - acc: 1.000 - ETA: 1s - loss: 2.7094e-04 - acc: 1.000 - ETA: 1s - loss: 2.7079e-04 - acc: 1.000 - ETA: 1s - loss: 2.7095e-04 - acc: 1.000 - ETA: 1s - loss: 2.7028e-04 - acc: 1.000 - ETA: 1s - loss: 2.6952e-04 - acc: 1.000 - ETA: 1s - loss: 2.6879e-04 - acc: 1.000 - ETA: 1s - loss: 2.6798e-04 - acc: 1.000 - ETA: 1s - loss: 2.6768e-04 - acc: 1.000 - ETA: 1s - loss: 2.6761e-04 - acc: 1.000 - ETA: 1s - loss: 2.6670e-04 - acc: 1.000 - ETA: 0s - loss: 2.6736e-04 - acc: 1.000 - ETA: 0s - loss: 2.6714e-04 - acc: 1.000 - ETA: 0s - loss: 2.6701e-04 - acc: 1.000 - ETA: 0s - loss: 2.6694e-04 - acc: 1.000 - ETA: 0s - loss: 2.6682e-04 - acc: 1.000 - ETA: 0s - loss: 2.6616e-04 - acc: 1.000 - ETA: 0s - loss: 2.6563e-04 - acc: 1.000 - ETA: 0s - loss: 2.6504e-04 - acc: 1.000 - ETA: 0s - loss: 2.6457e-04 - acc: 1.000 - ETA: 0s - loss: 2.6394e-04 - acc: 1.000 - ETA: 0s - loss: 2.6331e-04 - acc: 1.000 - ETA: 0s - loss: 2.6303e-04 - acc: 1.000 - ETA: 0s - loss: 2.6278e-04 - acc: 1.000 - ETA: 0s - loss: 2.6278e-04 - acc: 1.000 - ETA: 0s - loss: 2.6243e-04 - acc: 1.000 - ETA: 0s - loss: 2.6249e-04 - acc: 1.000 - ETA: 0s - loss: 2.6228e-04 - acc: 1.000 - ETA: 0s - loss: 2.6233e-04 - acc: 1.000 - ETA: 0s - loss: 2.6231e-04 - acc: 1.000 - ETA: 0s - loss: 2.6199e-04 - acc: 1.000 - 10s 381us/sample - loss: 2.6196e-04 - acc: 1.0000 - val_loss: 0.7765 - val_acc: 0.8265\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 10s - loss: 1.9851e-04 - acc: 1.00 - ETA: 5s - loss: 1.6828e-04 - acc: 1.0000 - ETA: 5s - loss: 1.4907e-04 - acc: 1.000 - ETA: 6s - loss: 1.5901e-04 - acc: 1.000 - ETA: 5s - loss: 1.6336e-04 - acc: 1.000 - ETA: 5s - loss: 1.6424e-04 - acc: 1.000 - ETA: 5s - loss: 1.6492e-04 - acc: 1.000 - ETA: 5s - loss: 1.6534e-04 - acc: 1.000 - ETA: 5s - loss: 1.6596e-04 - acc: 1.000 - ETA: 6s - loss: 1.7118e-04 - acc: 1.000 - ETA: 6s - loss: 1.7007e-04 - acc: 1.000 - ETA: 6s - loss: 1.7118e-04 - acc: 1.000 - ETA: 6s - loss: 1.7219e-04 - acc: 1.000 - ETA: 6s - loss: 1.7195e-04 - acc: 1.000 - ETA: 6s - loss: 1.7004e-04 - acc: 1.000 - ETA: 6s - loss: 1.7276e-04 - acc: 1.000 - ETA: 5s - loss: 1.7343e-04 - acc: 1.000 - ETA: 5s - loss: 1.7187e-04 - acc: 1.000 - ETA: 6s - loss: 1.7150e-04 - acc: 1.000 - ETA: 5s - loss: 1.7014e-04 - acc: 1.000 - ETA: 5s - loss: 1.6969e-04 - acc: 1.000 - ETA: 5s - loss: 1.6912e-04 - acc: 1.000 - ETA: 5s - loss: 1.6812e-04 - acc: 1.000 - ETA: 5s - loss: 1.6973e-04 - acc: 1.000 - ETA: 5s - loss: 1.7010e-04 - acc: 1.000 - ETA: 5s - loss: 1.7171e-04 - acc: 1.000 - ETA: 5s - loss: 1.7105e-04 - acc: 1.000 - ETA: 5s - loss: 1.6965e-04 - acc: 1.000 - ETA: 5s - loss: 1.6948e-04 - acc: 1.000 - ETA: 5s - loss: 1.6812e-04 - acc: 1.000 - ETA: 5s - loss: 1.6762e-04 - acc: 1.000 - ETA: 5s - loss: 1.6733e-04 - acc: 1.000 - ETA: 5s - loss: 1.6779e-04 - acc: 1.000 - ETA: 5s - loss: 1.6677e-04 - acc: 1.000 - ETA: 5s - loss: 1.6711e-04 - acc: 1.000 - ETA: 5s - loss: 1.6594e-04 - acc: 1.000 - ETA: 5s - loss: 1.6504e-04 - acc: 1.000 - ETA: 5s - loss: 1.6527e-04 - acc: 1.000 - ETA: 5s - loss: 1.6512e-04 - acc: 1.000 - ETA: 5s - loss: 1.6607e-04 - acc: 1.000 - ETA: 5s - loss: 1.6586e-04 - acc: 1.000 - ETA: 5s - loss: 1.6609e-04 - acc: 1.000 - ETA: 4s - loss: 1.6541e-04 - acc: 1.000 - ETA: 4s - loss: 1.6575e-04 - acc: 1.000 - ETA: 4s - loss: 1.6577e-04 - acc: 1.000 - ETA: 4s - loss: 1.6873e-04 - acc: 1.000 - ETA: 4s - loss: 1.6945e-04 - acc: 1.000 - ETA: 4s - loss: 1.6892e-04 - acc: 1.000 - ETA: 4s - loss: 1.6838e-04 - acc: 1.000 - ETA: 4s - loss: 1.6792e-04 - acc: 1.000 - ETA: 4s - loss: 1.6891e-04 - acc: 1.000 - ETA: 4s - loss: 1.6821e-04 - acc: 1.000 - ETA: 4s - loss: 1.6748e-04 - acc: 1.000 - ETA: 4s - loss: 1.6690e-04 - acc: 1.000 - ETA: 4s - loss: 1.6706e-04 - acc: 1.000 - ETA: 4s - loss: 1.6695e-04 - acc: 1.000 - ETA: 4s - loss: 1.6735e-04 - acc: 1.000 - ETA: 4s - loss: 1.6745e-04 - acc: 1.000 - ETA: 3s - loss: 1.6758e-04 - acc: 1.000 - ETA: 3s - loss: 1.6758e-04 - acc: 1.000 - ETA: 3s - loss: 1.6737e-04 - acc: 1.000 - ETA: 3s - loss: 1.6752e-04 - acc: 1.000 - ETA: 3s - loss: 1.6794e-04 - acc: 1.000 - ETA: 3s - loss: 1.6756e-04 - acc: 1.000 - ETA: 3s - loss: 1.6753e-04 - acc: 1.000 - ETA: 3s - loss: 1.6778e-04 - acc: 1.000 - ETA: 3s - loss: 1.6768e-04 - acc: 1.000 - ETA: 3s - loss: 1.6722e-04 - acc: 1.000 - ETA: 3s - loss: 1.6638e-04 - acc: 1.000 - ETA: 3s - loss: 1.6577e-04 - acc: 1.000 - ETA: 3s - loss: 1.6534e-04 - acc: 1.000 - ETA: 3s - loss: 1.6556e-04 - acc: 1.000 - ETA: 3s - loss: 1.6532e-04 - acc: 1.000 - ETA: 3s - loss: 1.6509e-04 - acc: 1.000 - ETA: 2s - loss: 1.6513e-04 - acc: 1.000 - ETA: 2s - loss: 1.6448e-04 - acc: 1.000 - ETA: 2s - loss: 1.6515e-04 - acc: 1.000 - ETA: 2s - loss: 1.6533e-04 - acc: 1.000 - ETA: 2s - loss: 1.6503e-04 - acc: 1.000 - ETA: 2s - loss: 1.6575e-04 - acc: 1.000 - ETA: 2s - loss: 1.6519e-04 - acc: 1.000 - ETA: 2s - loss: 1.6493e-04 - acc: 1.000 - ETA: 2s - loss: 1.6429e-04 - acc: 1.000 - ETA: 2s - loss: 1.6460e-04 - acc: 1.000 - ETA: 2s - loss: 1.6444e-04 - acc: 1.000 - ETA: 2s - loss: 1.6406e-04 - acc: 1.000 - ETA: 2s - loss: 1.6405e-04 - acc: 1.000 - ETA: 2s - loss: 1.6383e-04 - acc: 1.000 - ETA: 2s - loss: 1.6372e-04 - acc: 1.000 - ETA: 2s - loss: 1.6408e-04 - acc: 1.000 - ETA: 2s - loss: 1.6382e-04 - acc: 1.000 - ETA: 2s - loss: 1.6333e-04 - acc: 1.000 - ETA: 2s - loss: 1.6326e-04 - acc: 1.000 - ETA: 2s - loss: 1.6361e-04 - acc: 1.000 - ETA: 1s - loss: 1.6386e-04 - acc: 1.000 - ETA: 1s - loss: 1.6340e-04 - acc: 1.000 - ETA: 1s - loss: 1.6357e-04 - acc: 1.000 - ETA: 1s - loss: 1.6374e-04 - acc: 1.000 - ETA: 1s - loss: 1.6339e-04 - acc: 1.000 - ETA: 1s - loss: 1.6302e-04 - acc: 1.000 - ETA: 1s - loss: 1.6290e-04 - acc: 1.000 - ETA: 1s - loss: 1.6273e-04 - acc: 1.000 - ETA: 1s - loss: 1.6255e-04 - acc: 1.000 - ETA: 1s - loss: 1.6219e-04 - acc: 1.000 - ETA: 1s - loss: 1.6202e-04 - acc: 1.000 - ETA: 1s - loss: 1.6177e-04 - acc: 1.000 - ETA: 1s - loss: 1.6169e-04 - acc: 1.000 - ETA: 1s - loss: 1.6169e-04 - acc: 1.000 - ETA: 1s - loss: 1.6150e-04 - acc: 1.000 - ETA: 1s - loss: 1.6119e-04 - acc: 1.000 - ETA: 1s - loss: 1.6102e-04 - acc: 1.000 - ETA: 1s - loss: 1.6116e-04 - acc: 1.000 - ETA: 1s - loss: 1.6109e-04 - acc: 1.000 - ETA: 1s - loss: 1.6089e-04 - acc: 1.000 - ETA: 1s - loss: 1.6081e-04 - acc: 1.000 - ETA: 0s - loss: 1.6056e-04 - acc: 1.000 - ETA: 0s - loss: 1.6042e-04 - acc: 1.000 - ETA: 0s - loss: 1.6013e-04 - acc: 1.000 - ETA: 0s - loss: 1.5982e-04 - acc: 1.000 - ETA: 0s - loss: 1.5963e-04 - acc: 1.000 - ETA: 0s - loss: 1.5933e-04 - acc: 1.000 - ETA: 0s - loss: 1.5930e-04 - acc: 1.000 - ETA: 0s - loss: 1.5903e-04 - acc: 1.000 - ETA: 0s - loss: 1.5897e-04 - acc: 1.000 - ETA: 0s - loss: 1.5896e-04 - acc: 1.000 - ETA: 0s - loss: 1.5890e-04 - acc: 1.000 - ETA: 0s - loss: 1.5866e-04 - acc: 1.000 - ETA: 0s - loss: 1.5859e-04 - acc: 1.000 - ETA: 0s - loss: 1.5842e-04 - acc: 1.000 - ETA: 0s - loss: 1.5836e-04 - acc: 1.000 - ETA: 0s - loss: 1.5838e-04 - acc: 1.000 - ETA: 0s - loss: 1.5815e-04 - acc: 1.000 - ETA: 0s - loss: 1.5763e-04 - acc: 1.000 - ETA: 0s - loss: 1.5745e-04 - acc: 1.000 - ETA: 0s - loss: 1.5734e-04 - acc: 1.000 - 10s 393us/sample - loss: 1.5722e-04 - acc: 1.0000 - val_loss: 0.8150 - val_acc: 0.8260\n",
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
    "\n",
    "# To reverse indexs to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[3]))\n",
    "print(training_sentences[3])\n",
    "\n",
    "\n",
    "\n",
    "# Define a neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),  #--> output_shape = vocab_size, embeddd_dim\n",
    "    tf.keras.layers.Flatten(),     #OR     --> output_shape = 1920  which is equal to vocab_size* embeddd_dim\n",
    "#     tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile( loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fitting\n",
    "history = model.fit(padded, training_labels_final,\n",
    "          epochs=10,\n",
    "          validation_data=(testing_padded, testing_labels_final))\n",
    "\n",
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "\n",
    "# to visualize the vector data\n",
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, vocab_size):\n",
    "  word = reverse_word_index [word_num]\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "\n",
    "# To download the files\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')\n",
    "\n",
    "# To visualizing data go to http://projector.tensorflow.org/ load vecs.tsv for the step1 and meta.tsv for step 2.\n",
    "#     tick Sphereize data  box to see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "WARNING:matplotlib.style.core:In C:\\Users\\Leila\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
